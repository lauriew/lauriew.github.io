@incollection{bodden2023empirical,
  title={Empirical Evaluation of Secure Development Processes (Dagstuhl Seminar 23181)},
  author={Bodden, Eric and Weber, Sam and Williams, Laurie},
  journal={Dagstuhl Reports},
  volume={13},
  number={5},
  pages={1--21},
  year={2023},
  publisher={Schloss Dagstuhl--Leibniz-Zentrum f{\"u}r Informatik},
  url={https://drops.dagstuhl.de/entities/document/10.4230/DagRep.13.5.1}
}

@incollection{williams2020continuous,
  title={Continuous Deployment Transitions at Scale},
  author={Williams, Laurie and Beck, Kent and Creasey, Jeffrey and Glover, Andrew and Holman, James and Humble, Jez and McLaughlin, David and Micco, John Thomas and Murphy, Brendan and Cox, Jason A and others},
  booktitle={Tools and Techniques for Software Development in Large Organizations: Emerging Research and Opportunities},
  pages={168--181},
  year={2020},
  publisher={IGI Global Scientific Publishing},
  url={https://www.igi-global.com/chapter/continuous-deployment-transitions-at-scale/247542}
}

@book{huhn2017software,
  title={Software Engineering in Health Care},
  author={Huhn, Michaela and Williams, Laurie},
  year={2017},
  publisher={Springer},
  url={https://link.springer.com/content/pdf/10.1007/978-3-319-63194-3.pdf}
}

@book{menzies2016perspectives,
  title={Perspectives on data science for software engineering},
  author={Menzies, Tim and Williams, Laurie and Zimmermann, Thomas},
  year={2016},
  publisher={Morgan Kaufmann},
  url={https://books.google.com/books?hl=en&lr=&id=Kc7nCQAAQBAJ&oi=fnd&pg=PP1&dq=title%3D%7BPerspectives+on+data+science+for+software+engineering%7D,&ots=l_RjKy8RJa&sig=_Mm8C56jQCup7JdSNlnEaqGtmbE}
}

@incollection{murphy2015using,
  title={Using Data to Make Decisions in Software Engineering: Providing a Method to our Madness},
  author={Murphy, Brendan and Czerwonka, Jacek and Williams, Laurie},
  booktitle={The Art and Science of Analyzing Software Data},
  pages={349--375},
  year={2015},
  publisher={Elsevier},
  url={https://www.sciencedirect.com/science/article/pii/B9780124115194000136}
}

@incollection{williamsitrust,
  title={iTrust electronic health care system},
  author={Williams, L and Meneely, A and Smith, S and Hayward, L and Smith, B and King, J},
  year={2012},
  url={https://link.springer.com/content/pdf/10.1007/978-1-4471-2239-5.pdf#page=430}
}

@inproceedings{riaz2016systematically,
  title={Systematically developing prevention, detection, and response patterns for security requirements},
  author={Riaz, Maria and Elder, Sarah and Williams, Laurie},
  booktitle={2016 IEEE 24th International Requirements Engineering Conference Workshops (REW)},
  pages={62--67},
  year={2016},
  organization={IEEE},
  url={https://ieeexplore.ieee.org/abstract/document/7815608/?casa_token=1FwJy1MtaxwAAAAA:in4SqNpi6OpH5_GKiTc4JojwMTcywOyD3KxkZHTxEwjJFVClK5MjcVSYvq8iPRBT_zLln28}
}

@inproceedings{10.1145/2896941.2896946,
author = {Ur Rahman, Akond Ashfaque and Williams, Laurie},
title = {Software security in DevOps: synthesizing practitioners' perceptions and practices},
year = {2016},
isbn = {9781450341578},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2896941.2896946},
doi = {10.1145/2896941.2896946},
abstract = {In organizations that use DevOps practices, software changes can be deployed as fast as 500 times or more per day. Without adequate involvement of the security team, rapidly deployed software changes are more likely to contain vulnerabilities due to lack of adequate reviews. The goal of this paper is to aid software practitioners in integrating security and DevOps by summarizing experiences in utilizing security practices in a DevOps environment. We analyzed a selected set of Internet artifacts and surveyed representatives of nine organizations that are using DevOps to systematically explore experiences in utilizing security practices. We observe that the majority of the software practitioners have expressed the potential of common DevOps activities, such as automated monitoring, to improve the security of a system. Furthermore, organizations that integrate DevOps and security utilize additional security activities, such as security requirements analysis and performing security configurations. Additionally, these teams also have established collaboration between the security team and the development and operations teams.},
booktitle = {Proceedings of the International Workshop on Continuous Software Evolution and Delivery},
pages = {70–76},
numpages = {7},
keywords = {survey, software practices, security, DevOps},
location = {Austin, Texas},
series = {CSED '16}
}

@inproceedings{10.1145/2898375.2898383,
author = {Ur Rahman, Akond Ashfaque and Williams, Laurie},
title = {Security practices in DevOps},
year = {2016},
isbn = {9781450342773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2898375.2898383},
doi = {10.1145/2898375.2898383},
abstract = {DevOps focuses on collaboration between different teams in an organization to achieve rapid deployment of software and services to end-users by automating the software delivery infrastructure. According to Dyck et al. [1] DevOps is a software process that emphasizes collaboration within and between different teams involved in software development. According to a study from CA Technologies [5], 88\% of 1425 organization executives stated that they have adopted DevOps, or are planning to adopt DevOps in the next five years. According to Puppet Labs' 2015 State of DevOps Report [2], organizations that have adopted DevOps experienced 60 times fewer failures and deploy 30 times more frequently than organizations that have not adopted DevOps. Despite the popularity, security aspects of DevOps remain a concern for organizations that want to adopt DevOps [5]. In organizations that use DevOps practices, developers can commit and deploy their software changes at a rapid rate using an automated pipeline. At such a rapid rate, if the security team operates in isolation without close collaboration with the development and operations teams, then the rapidly deployed software changes might not undergo the adequate security reviews, potentially leading to vulnerable software. Bringing security principles within the DevOps process can help the organization in achieving better quality of software by integrating security checks into the phases of development, testing, and deployment.},
booktitle = {Proceedings of the Symposium and Bootcamp on the Science of Security},
pages = {109–111},
numpages = {3},
location = {Pittsburgh, Pennsylvania},
series = {HotSos '16}
}

@inproceedings{10.1145/2898375.2898388,
author = {Theisen, Christopher and Williams, Laurie},
title = {Risk-based attack surface approximation: poster},
year = {2016},
isbn = {9781450342773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2898375.2898388},
doi = {10.1145/2898375.2898388},
abstract = {Proactive security review and test efforts are a necessary component of the software development lifecycle. Since resource limitations often preclude reviewing, testing and fortifying the entire code base, prioritizing what code to review/test can improve a team's ability to find and remove more vulnerabilities that are reachable by an attacker. One way that professionals perform this prioritization is the identification of the attack surface of software systems. However, identifying the attack surface of a software system is non-trivial. The goal of this poster is to present the concept of a risk-based attack surface approximation based on crash dump stack traces for the prioritization of security code rework efforts. For this poster, we will present results from previous efforts in the attack surface approximation space, including studies on its effectiveness in approximating security relevant code for Windows and Firefox. We will also discuss future research directions for attack surface approximation, including discovery of additional metrics from stack traces and determining how many stack traces are required for a good approximation.},
booktitle = {Proceedings of the Symposium and Bootcamp on the Science of Security},
pages = {121–123},
numpages = {3},
keywords = {stack traces, security, metrics, crash dumps, attack surface},
location = {Pittsburgh, Pennsylvania},
series = {HotSos '16}
}

@inproceedings{10.1145/2898375.2898386,
author = {Kafali, Ozgur and Singh, Munindar P. and Williams, Laurie},
title = {Toward a normative approach for forensicability},
year = {2016},
isbn = {9781450342773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2898375.2898386},
doi = {10.1145/2898375.2898386},
abstract = {Sociotechnical systems (STSs), where users interact with software components, support automated logging, i.e., what a user has performed in the system. However, most systems do not implement automated processes for inspecting the logs when a misuse happens. Deciding what needs to be logged is crucial as excessive amounts of logs might be overwhelming for human analysts to inspect. The goal of this research is to aid software practitioners to implement automated forensic logging by providing a systematic method of using attackers' malicious intentions to decide what needs to be logged. We propose Lokma: a normative framework to construct logging rules for forensic knowledge. We describe the general forensic process of Lokma, and discuss related directions.},
booktitle = {Proceedings of the Symposium and Bootcamp on the Science of Security},
pages = {65–67},
numpages = {3},
keywords = {sociotechnical systems, social norms, security, requirements, forensic logging},
location = {Pittsburgh, Pennsylvania},
series = {HotSos '16}
}

@INPROCEEDINGS{6890522,
  author={Hibshi, Hanan and Breaux, Travis and Riaz, Maria and Williams, Laurie},
  booktitle={2014 IEEE 1st International Workshop on Evolving Security and Privacy Requirements Engineering (ESPRE)}, 
  title={Towards a framework to measure security expertise in requirements analysis}, 
  year={2014},
  volume={},
  number={},
  pages={13-18},
  keywords={Interviews;Uncertainty;Encoding;Decision making;Firewalls (computing);Software;Security;requirements analysis;patterns;decision-making;situation awareness},
  doi={10.1109/ESPRE.2014.6890522},
  url={https://ieeexplore.ieee.org/abstract/document/6890522/?casa_token=RAJ2-nLbjM0AAAAA:Gp0kquMzK2_dcsHi4CIGGSollZbzshFXu6rclNYKKiURGHqtLlJ8yIU4PQ4QN60pfmVm2Tw}
}

@INPROCEEDINGS{6901633,
  author={Rivers, Anthony Thyron and Vouk, Mladen A. and Williams, Laurie A.},
  booktitle={2014 IEEE Eighth International Conference on Software Security and Reliability-Companion}, 
  title={On Coverage-Based Attack Profiles}, 
  year={2014},
  volume={},
  number={},
  pages={5-6},
  keywords={Mathematical model;Software reliability;Testing;Software;IP networks;Equations;Computational modeling;security;coverage;models;attack;profile},
  doi={10.1109/SERE-C.2014.15},
  url={https://ieeexplore.ieee.org/abstract/document/6901633/}
}

@inproceedings{10.1145/2600176.2600211,
author = {Subramani, Shweta and Vouk, Mladen and Williams, Laurie},
title = {An analysis of Fedora security profile},
year = {2014},
isbn = {9781450329071},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2600176.2600211},
doi = {10.1145/2600176.2600211},
abstract = {This paper examines security faults/vulnerabilities reported for Fedora. Results indicate that, at least in some situations, fault roughly constant may be used to guide estimation of residual vulnerabilities in an already released product, as well as possibly guide testing of the next version of the product.},
booktitle = {Proceedings of the 2014 Symposium and Bootcamp on the Science of Security},
incollection = {35},
numpages = {2},
keywords = {vulnerabilities, security faults, prediction, non-operational testing, detection, Fedora},
location = {Raleigh, North Carolina, USA},
series = {HotSoS '14}
}

@inproceedings{10.1145/2600176.2600204,
author = {Hwang, JeeHyun and Williams, Laurie and Vouk, Mladen},
title = {Access control policy evolution: an empirical study},
year = {2014},
isbn = {9781450329071},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2600176.2600204},
doi = {10.1145/2600176.2600204},
abstract = {Access Control Policies (ACPs) evolve. Understanding the trends and evolution patterns of ACPs could provide guidance about the reliability and maintenance of ACPs. Our research goal is to help policy authors improve the quality of ACP evolution based on the understanding of trends and evolution patterns in ACPs We performed an empirical study by analyzing the ACP changes over time for two systems: Security Enhanced Linux (SELinux), and an open-source virtual computing platform (VCL). We measured trends in terms of the number of policy lines and lines of code (LOC), respectively. We observed evolution patterns. For example, an evolution pattern st1 → st2 says that st1 (e.g., "read") evolves into st2 (e.g., "read" and "write"). This pattern indicates that policy authors add "write" permission in addition to existing "read" permission. We found that some of evolution patterns appear to occur more frequently.},
booktitle = {Proceedings of the 2014 Symposium and Bootcamp on the Science of Security},
incollection = {28},
numpages = {2},
keywords = {evolution, access control policy},
location = {Raleigh, North Carolina, USA},
series = {HotSoS '14}
}

@INPROCEEDINGS{6688857,
  author={Subramani, Shweta and Vouk, Mladen and Williams, Laurie},
  booktitle={2013 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)}, 
  title={Non-operational testing of software for security issues}, 
  year={2013},
  volume={},
  number={},
  pages={21-22},
  keywords={Security;Testing;Software;Software reliability;Educational institutions;Computer science;security faults;vulnerabilities;non-operational testing;detection;prediction},
  doi={10.1109/ISSREW.2013.6688857},
  url={https://ieeexplore.ieee.org/abstract/document/6688857/?casa_token=5lkloQQkSpcAAAAA:Qbwn2v1XntT0n4P-X64oM49wraiN0Du-Hi032ga8dQtXNhVe9RotzdzKxpETUe2olhv_t5A}
}

@INPROCEEDINGS{6688858,
  author={Lee, Da Young and Vouk, Mladen and Williams, Laurie},
  booktitle={2013 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)}, 
  title={Using software reliability models for security assessment — Verification of assumptions}, 
  year={2013},
  volume={},
  number={},
  pages={23-24},
  keywords={Security;Exponential distribution;Predictive models;Software reliability;Computational modeling;Abstracts},
  doi={10.1109/ISSREW.2013.6688858},
  url={https://ieeexplore.ieee.org/abstract/document/6688858/?casa_token=yLPDnWbXIVAAAAAA:li9B-KhqswWxwjy_BDSrs-ZZDi85IuCIlQ4m9mHQQ5-JWU79KQA8bmoo2QuSZrCXbXX2wA0}
}

@INPROCEEDINGS{6688869,
  author={Murphy, Brendan and Williams, Laurie},
  booktitle={2013 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)}, 
  title={To branch or not to branch that is the question}, 
  year={2013},
  volume={},
  number={},
  pages={55-55},
  keywords={Abstracts;Software as a service},
  doi={10.1109/ISSREW.2013.6688869},
  url={https://ieeexplore.ieee.org/abstract/document/6688869}
}

@INPROCEEDINGS{6611715,
  author={Slankas, John and Williams, Laurie},
  booktitle={2013 1st International Workshop on Natural Language Analysis in Software Engineering (NaturaLiSE)}, 
  title={Automated extraction of non-functional requirements in available documentation}, 
  year={2013},
  volume={},
  number={},
  pages={9-16},
  keywords={Natural languages;Classification algorithms;Measurement;Documentation;Standards;Security;Machine learning algorithms;non-functional requirements;natural language processing;machine learning;classification;documentation},
  doi={10.1109/NAturaLiSE.2013.6611715},
  url={https://ieeexplore.ieee.org/abstract/document/6611715}
}

@INPROCEEDINGS{6602477,
  author={Morrison, Patrick and Holmgreen, Casper and Massey, Aaron and Williams, Laurie},
  booktitle={2013 5th International Workshop on Software Engineering in Health Care (SEHC)}, 
  title={Proposing regulatory-driven automated test suites for electronic health record systems}, 
  year={2013},
  volume={},
  number={},
  pages={46-49},
  keywords={Data structures;Boolean functions;NIST;Certification;Behavior-Driven-Development Healthcare IT;Regulatory Compliance;Security;Software Engineering;Software Testing},
  doi={10.1109/SEHC.2013.6602477},
  url={https://ieeexplore.ieee.org/abstract/document/6602477/}
}

@article{king2012secure,
  title={Secure Logging and Auditing in Electronic Health Records Systems: What Can We Learn from the Payment Card Industry Position Paper},
  author={King, Jason and Williams, Laurie},
  journal={Usenix HealthSec'12},
  year={2012},
  url={https://www.usenix.org/conference/healthsec12/workshop-program/presentation/king}
}

@inproceedings{morrison2012analysis,
  title={An Analysis of HIPAA Breach Data.},
  author={Morrison, Patrick and Williams, Laurie A},
  booktitle={HealthSec},
  year={2012},
  url={https://www.usenix.org/conference/healthsec12/workshop-program/presentation/morrison}
}

@INPROCEEDINGS{6359977,
  author={Riaz, Maria and Williams, Laurie},
  booktitle={2012 Second IEEE International Workshop on Requirements Patterns (RePa)}, 
  title={Security requirements patterns: understanding the science behind the art of pattern writing}, 
  year={2012},
  volume={},
  number={},
  pages={29-34},
  keywords={Security;Software;Standards;Writing;Context;Testing;Maintenance engineering;Security Requirements Patterns;Software Patterns;Empirical Development of Patterns},
  doi={10.1109/RePa.2012.6359977},
  url={https://ieeexplore.ieee.org/abstract/document/6359977/}
}

@INPROCEEDINGS{6223002,
  author={Murphy-Hill, Emerson and Williams, Laurie},
  booktitle={2012 5th International Workshop on Co-operative and Human Aspects of Software Engineering (CHASE)}, 
  title={How can research about software developers generalize?}, 
  year={2012},
  volume={},
  number={},
  pages={105-109},
  keywords={Software;Programming;Software engineering;USA Councils;Context;Computers;Visualization;software development;generalization;research},
  doi={10.1109/CHASE.2012.6223002},
  url={https://ieeexplore.ieee.org/abstract/document/6223002/}
}

@INPROCEEDINGS{6050266,
  author={Young Schmidt, Jessica and Antón, Annie I. and Williams, Laurie and Otto, Paul N.},
  booktitle={2011 Fourth International Workshop on Requirements Engineering and Law}, 
  title={The role of data use agreements in specifying legally compliant software requirements}, 
  year={2011},
  volume={},
  number={},
  pages={1-4},
  keywords={Natural languages;Privacy;Law;Medical services;Software;Organizations;requirements;data use agreements;HIPAA;legal compliance;commitments;privileges;rights;contractual compliance requirements},
  doi={10.1109/RELAW.2011.6050266},
  url={https://ieeexplore.ieee.org/abstract/document/6050266}
}

@inproceedings{10.1145/1988630.1988632,
author = {Shin, Yonghee and Williams, Laurie},
title = {An initial study on the use of execution complexity metrics as indicators of software vulnerabilities},
year = {2011},
isbn = {9781450305815},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1988630.1988632},
doi = {10.1145/1988630.1988632},
abstract = {Allocating code inspection and testing resources to the most problematic code areas is important to reduce development time and cost. While complexity metrics collected statically from software artifacts are known to be helpful in finding vulnerable code locations, some complex code is rarely executed in practice and has less chance of its vulnerabilities being detected. To augment the use of static complexity metrics, this study examines execution complexity metrics that are collected during code execution as indicators of vulnerable code locations. We conducted case studies on two large size, widely-used open source projects, the Mozilla Firefox web browser and the Wireshark network protocol analyzer. Our results indicate that execution complexity metrics are better indicators of vulnerable code locations than the most commonly-used static complexity metric, lines of source code. The ability of execution complexity metrics to discriminate vulnerable code locations from neutral code locations and to predict vulnerable code locations vary depending on projects. However, the vulnerability prediction models using execution complexity metrics are superior to the models using static complexity metrics in reducing inspection effort.},
booktitle = {Proceedings of the 7th International Workshop on Software Engineering for Secure Systems},
pages = {1–7},
numpages = {7},
keywords = {complexity metrics, execution metrics, software security, software vulnerability prediction},
location = {Waikiki, Honolulu, HI, USA},
series = {SESS '11}
}

@inproceedings{10.1145/1987993.1988006,
author = {Helms, Eric and Williams, Laurie},
title = {Evaluating access control of open source electronic health record systems},
year = {2011},
isbn = {9781450305853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1987993.1988006},
doi = {10.1145/1987993.1988006},
abstract = {Incentives and penalties for healthcare providers as laid out in the American Recovery and Reinvestment Act of 2009 have caused tremendous growth in the development and installation of electronic health record (EHR) systems in the US. For the benefit of protecting patient privacy, regulations and certification criteria related to EHR systems stipulate the use of access control of protected health information. The goal of this research is to guide development teams, regulators, and certification bodies by assessing the state of the practice in EHR access control. In this paper, we present a compilation of 25 criteria relative to access control in EHR systems found in the Health Insurance Portability and Accountability Act (HIPAA) regulation, meaningful use certification criteria, best practices embodied in the National Institute for Standards and Technology (NIST) role-based access control standard, and other best practices found in the literature. We then examine the state of the practice in access control by evaluating four open source EHR systems using these 25 evaluation criteria. Our research indicates that the NIST Meaningful Use criteria provide HIPAA compliance, but none of the regulatory and certification criteria address the implementation standards, and best practices related to access control. Additionally, our results indicate that open source EHR system designers are not implementing robust access control mechanisms for the adequate protection of patient data.},
booktitle = {Proceedings of the 3rd Workshop on Software Engineering in Health Care},
pages = {63–70},
numpages = {8},
keywords = {access control, electronic health records, health it, healthcare, privacy, role-based access control},
location = {Waikiki, Honolulu, HI, USA},
series = {SEHC '11}
}

@inproceedings{10.1145/1866914.1866916,
author = {Smith, Ben and Austin, Andrew and Brown, Matt and King, Jason T. and Lankford, Jerrod and Meneely, Andrew and Williams, Laurie},
title = {Challenges for protecting the privacy of health information: required certification can leave common vulnerabilities undetected},
year = {2010},
isbn = {9781450300940},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1866914.1866916},
doi = {10.1145/1866914.1866916},
abstract = {The use of electronic health record (EHR) systems by medical professionals enables the electronic exchange of patient data, yielding cost and quality of care benefits. The United States American Recovery and Reinvestment Act (ARRA) of 2009 provides up to $34 billion for meaningful use of certified EHR systems. But, will these certified EHR systems provide the infrastructure for secure patient data exchange? As a window into the ability of current and emerging certification criteria to expose security vulnerabilities, we performed exploratory security analysis on a proprietary and an open source EHR. We were able to exploit a range of common code-level and design-level vulnerabilities. These common vulnerabilities would have remained undetected by the 2011 security certification test scripts from the Certification Commission for Health Information Technology, the most widely used certification process for EHR systems. The consequences of these exploits included, but were not limited to: exposing all users' login information, the ability of any user to view or edit health records for any patient, and creating a denial of service for all users. Based upon our results, we suggest that an enhanced set of security test scripts be used as entry criteria to the EHR certification process. Before certification bodies spend the time to certify that an EHR application is functionally complete, they should have confidence that the software system meets a basic level of security competence.},
booktitle = {Proceedings of the Second Annual Workshop on Security and Privacy in Medical and Home-Care Systems},
pages = {1–12},
numpages = {12},
keywords = {attack, cchit, dos, ehr, emr, ethical hacking, exploit, healthcare, man-in-the-middle, meaningful use, medical records, openemr, security testing, sql injection, vulnerability, white hat, xss},
location = {Chicago, Illinois, USA},
series = {SPIMACS '10}
}

@inproceedings{austin2010towards,
  title={Towards improved security criteria for certification of electronic health record systems},
  author={Austin, Andrew and Smith, Ben and Williams, Laurie},
  booktitle={Proceedings of the 2010 ICSE Workshop on Software Engineering in Health Care},
  pages={68--73},
  year={2010},
  url={https://dl.acm.org/doi/abs/10.1145/1809085.1809094?casa_token=nDrsQB1MyCAAAAAA:zHvMs4Ox9djqS3w2e6BiG8avsBb6rKcji9_k4itNN4q9Nx2YBe8BrjxF41NpcRnABJlsgPspdMM}
}

@INPROCEEDINGS{4700353,
  author={Gegick, Michael and Williams, Laurie},
  booktitle={2008 19th International Symposium on Software Reliability Engineering (ISSRE)}, 
  title={Ranking Attack-Prone Components with a Predictive Model}, 
  year={2008},
  volume={},
  number={},
  pages={315-316},
  keywords={Predictive models;Security;Performance analysis;Input variables;Buffer overflow;Software systems;Risk analysis;Classification tree analysis;Regression tree analysis;Failure analysis;Attack-prone},
  doi={10.1109/ISSRE.2008.24},
  url={https://ieeexplore.ieee.org/abstract/document/4700353/?casa_token=MpF3IEjG8DsAAAAA:iHHOqjFXO-NvR7qrzHCeShXW3t3bqHEUEPGqadB3hCCpWnKfC4TACa4TMOn1AbkGWU8gg5Y}
}

@inproceedings{10.1145/1449814.1449866,
author = {Fraser, Steven and Campara, Djenana and Gleichauf, Robert and Pearson, Harriet and Swire, Peter and Williams, Laurie},
title = {Privacy and security: what are you doing to keep the community safe?},
year = {2008},
isbn = {9781605582207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1449814.1449866},
doi = {10.1145/1449814.1449866},
abstract = {In a networked "always on" world, robust corporate and personal security and privacy strategies are increasingly necessary to ensure that the unintended consequences of implementations do not spin impossibly "out-of-control". How do systems and by extension their designers, implementers, owners and users balance the desire for an open world community with the issues of individual privacy and community safety? What questions should business people, scientists, engineers, and researchers ask and what strategies should they consider as they discover requirements, develop systems, and deploy products? Issues from data misuse and encryption strategies to social engineering and meeting the challenge of identity theft (are you really "you"?) are no longer ignorable.},
booktitle = {Companion to the 23rd ACM SIGPLAN Conference on Object-Oriented Programming Systems Languages and Applications},
pages = {801–804},
numpages = {4},
keywords = {security, privacy, policy},
location = {Nashville, TN, USA},
series = {OOPSLA Companion '08}
}

@inproceedings{10.1145/1456362.1456372,
author = {Shin, Yonghee and Williams, Laurie},
title = {Is complexity really the enemy of software security?},
year = {2008},
isbn = {9781605583211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1456362.1456372},
doi = {10.1145/1456362.1456372},
abstract = {Software complexity is often hypothesized to be the enemy of software security. We performed statistical analysis on nine code complexity metrics from the JavaScript Engine in the Mozilla application framework to investigate if this hypothesis is true. Our initial results show that the nine complexity measures have weak correlation (ρ=0.30 at best) with security problems for Mozilla JavaScript Engine. The study should be replicated on more products with design and code-level metrics. It may be necessary to create new complexity metrics to embody the type of complexity that leads to security problems.},
booktitle = {Proceedings of the 4th ACM Workshop on Quality of Protection},
pages = {47–50},
numpages = {4},
keywords = {fault prediction, reliability, security metrics, software complexity, software metrics, vulnerability prediction},
location = {Alexandria, Virginia, USA},
series = {QoP '08}
}

@inproceedings{10.1145/1456362.1456370,
author = {Gegick, Michael and Williams, Laurie and Osborne, Jason and Vouk, Mladen},
title = {Prioritizing software security fortification throughcode-level metrics},
year = {2008},
isbn = {9781605583211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1456362.1456370},
doi = {10.1145/1456362.1456370},
abstract = {Limited resources preclude software engineers from finding and fixing all vulnerabilities in a software system. We create predictive models to identify which components are likely to have the most security risk. Software engineers can use these models to make measurement-based risk management decisions and to prioritize software security fortification efforts, such as redesign and additional inspection and testing. We mined and analyzed data from a large commercial telecommunications software system containing over one million lines of code that had been deployed to the field for two years. Using recursive partitioning, we built attack-prone prediction models with the following code-level metrics: static analysis tool alert density, code churn, and count of source lines of code. One model identified 100\% of the attack-prone components (40\% of the total number of components) with an 8\% false positive rate. As such, the model could be used to prioritize fortification efforts in the system.},
booktitle = {Proceedings of the 4th ACM Workshop on Quality of Protection},
pages = {31–38},
numpages = {8},
keywords = {vulnerability-prone, attack-prone},
location = {Alexandria, Virginia, USA},
series = {QoP '08}
}

@inproceedings{10.1145/1370905.1370912,
author = {Smith, Ben and Shin, Yonghee and Williams, Laurie},
title = {Proposing SQL statement coverage metrics},
year = {2008},
isbn = {9781605580425},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1370905.1370912},
doi = {10.1145/1370905.1370912},
abstract = {An increasing number of cyber attacks are occurring at the application layer when attackers use malicious input. These input validation vulnerabilities can be exploited by (among others) SQL injection, cross site scripting, and buffer overflow attacks. Statement coverage and similar test adequacy metrics have historically been used to assess the level of functional and unit testing which has been performed on an application. However, these currently-available metrics do not highlight how well the system protects itself through validation. In this paper, we propose two SQL injection input validation testing adequacy metrics: target statement coverage and input variable coverage. A test suite which satisfies both adequacy criteria can be leveraged as a solid foundation for input validation scanning with a blacklist. To determine whether it is feasible to calculate values for our two metrics, we perform a case study on a web healthcare application and discuss some issues in implementation we have encountered. We find that the web healthcare application scored 96.7\% target statement coverage and 98.5\% input variable coverage.},
booktitle = {Proceedings of the Fourth International Workshop on Software Engineering for Secure Systems},
pages = {49–56},
numpages = {8},
keywords = {threat, test, security, coverage criteria, attack, SQL injection, SQL},
location = {Leipzig, Germany},
series = {SESS '08}
}

@inproceedings{10.1145/1370114.1370133,
author = {Layman, Lucas M. and Williams, Laurie A. and St. Amant, Robert},
title = {MimEc: intelligent user notification of faults in the eclipse IDE},
year = {2008},
isbn = {9781605580395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1370114.1370133},
doi = {10.1145/1370114.1370133},
abstract = {The earlier in the software process a fault is detected, the cheaper the cost of fixing the fault. Automated fault detection tools can provide developers with information throughout development, however, programming is a cognitively complex process and inundating the developer with information may do more harm than good. In this paper, we present MimEc, a part of the AWARE plug-in for the Eclipse integrated development environment. MimEc presents fault information to developers while they are writing code. The purpose of MimEc is to display only those faults in which a developer may be interested, thereby increasing the likelihood the developer will address the fault. MimEc infers interest in a fault based on fault criticality, relevance of the fault to the developer's current working context, and the developer's interactions with the programming environment. MimEc is currently under development and will be evaluated in both academic and professional settings.},
booktitle = {Proceedings of the 2008 International Workshop on Cooperative and Human Aspects of Software Engineering},
pages = {73–76},
numpages = {4},
keywords = {psychology of programming, intelligent IDE},
location = {Leipzig, Germany},
series = {CHASE '08}
}

@INPROCEEDINGS{4344124,
  author={Smith, Ben H. and Williams, Laurie},
  booktitle={Testing: Academic and Industrial Conference Practice and Research Techniques - MUTATION (TAICPART-MUTATION 2007)}, 
  title={An Empirical Evaluation of the MuJava Mutation Operators}, 
  year={2007},
  volume={},
  number={},
  pages={193-202},
  keywords={Genetic mutations;Java;Computer industry;Computer science;Automatic testing;Fault detection;Medical services;Application software;Character generation;Computer aided instruction},
  doi={10.1109/TAIC.PART.2007.12},
  url={https://ieeexplore.ieee.org/abstract/document/4344124/}
}

@inproceedings{gegick2007correlating,
  title={Correlating Automated Static Analysis Alert Density to Reported Vulnerabilities in Sendmail},
  author={Gegick, Michael and Williams, Laurie},
  booktitle={Proc of the MetriCon 2.0 at 16th USENIX Security Symposium (Security'07)},
  year={2007},
  organization={Citeseer}
}

@inproceedings{10.1145/1295014.1295042,
author = {Sherriff, Mark S. and Heckman, Sarah Smith and Lake, J. Michael and Williams, Laurie A.},
title = {Using groupings of static analysis alerts to identify files likely to contain field failures},
year = {2007},
isbn = {9781595938121},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1295014.1295042},
doi = {10.1145/1295014.1295042},
abstract = {In this paper, we propose a technique for leveraging historical field failure records in conjunction with automated static analysis alerts to determine which alerts or sets of alerts are predictive of a field failure. Our technique uses singular value decomposition to generate groupings of static analysis alert types, which we call alert signatures, that have been historically linked to field failure-prone files in previous releases of a software system. The signatures can be applied to sets of alerts from a current build of a software system. Files that have a matching alert signature are identified as having similar static analysis alert characteristics to files with known field failures in a previous release of the system. We performed a case study involving an industrial software system at IBM and found three distinct alert signatures that could be applied to the system. We found that 50\% of the field failures reported since the last static analysis run could be discovered by examining the 10\% of the files and static analysis alerts indicated by these three alert signatures. The remaining failures were either not detected by a signature which could be an indication of a new type of error in the field, or they were on areas of the code where no static analysis alerts were detected.},
booktitle = {The 6th Joint Meeting on European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering: Companion Papers},
pages = {565–568},
numpages = {4},
keywords = {field failures, singular value decomposition, static analysis},
location = {Dubrovnik, Croatia},
series = {ESEC-FSE companion '07}
}

@INPROCEEDINGS{4271764,
  author={Gegick, Michael and Williams, Laurie},
  booktitle={Second International Conference on Internet Monitoring and Protection (ICIMP 2007)}, 
  title={Toward the Use of Automated Static Analysis Alerts for Early Identification of Vulnerability- and Attack-prone Components}, 
  year={2007},
  volume={},
  number={},
  pages={18-18},
  keywords={Fault diagnosis;Software systems;Software metrics;Software quality;Security;Testing;Risk analysis;Knowledge engineering;Risk management;Inspection},
  doi={10.1109/ICIMP.2007.46},
  url={https://ieeexplore.ieee.org/abstract/document/4271764/?casa_token=aFZ7J_uXK0sAAAAA:TjQ3uFg5Xm8prR8t5CtgOBR41v4nN-Yg9genaShOimgxNj673zkNIqKBONLGqg3KBm5jQsLgSlc}
}

@INPROCEEDINGS{4273335,
  author={Thomas, Stephen and Williams, Laurie},
  booktitle={Third International Workshop on Software Engineering for Secure Systems (SESS'07: ICSE Workshops 2007)}, 
  title={Using Automated Fix Generation to Secure SQL Statements}, 
  year={2007},
  volume={},
  number={},
  pages={9-9},
  keywords={Java;Information security;Databases;Input variables;Computer science;Automatic testing;Automation;Code standards;Standards development;Programming},
  doi={10.1109/SESS.2007.12},
  url={https://ieeexplore.ieee.org/abstract/document/4273335/}
}

@INPROCEEDINGS{4273235,
  author={Zheng, Jiang and Williams, Laurie and Robinson, Brian and Smiley, Karen},
  booktitle={Second International Workshop on Incorporating COTS Software into Software Systems: Tools and Techniques (IWICSS '07)}, 
  title={Regression Test Selection for Black-box Dynamic Link Library Components}, 
  year={2007},
  volume={},
  number={},
  pages={9-9},
  keywords={System testing;Software testing;Binary codes;Software systems;Software libraries;Computer science;Costs;Hardware;Software tools;Documentation},
  doi={10.1109/IWICSS.2007.8},
  url={https://ieeexplore.ieee.org/abstract/document/4273235/?casa_token=u7qqv57e4msAAAAA:dabdytg2JHia1TBmr-HESKH7NJ-qaGkTIxiN9J7qJVo9jwZZ_WU8MYAgnOUo7EQyPeRZAzxtk-M}
}

@inproceedings{williams2007increasing,
  title={On Increasing System Test Effectiveness through a Test Case Prioritization Model Using Static Metrics and System Failure Data},
  author={Williams, Laurie and Snipes, Will and Meneely, Andrew},
  booktitle={Reliability Analysis of System Failure Data Workshop},
  year={2007},
  url={https://www.academia.edu/download/48034083/Hotspot_Deeds.pdf}
}

@inproceedings{10.1145/1216993.1217016,
author = {Ho, Chih-Wei and Williams, Laurie},
title = {Developing software performance with the performance refinement and evolution model},
year = {2007},
isbn = {1595932976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1216993.1217016},
doi = {10.1145/1216993.1217016},
abstract = {Performance is an important attribute of a software system. To develop a software system of acceptable performance, the team needs to specify precise performance requirements, design appropriate test cases, and use suitable techniques to analyze the performance characteristics. However, the lack of a structured framework for performance engineering may impair the effectiveness of the techniques. We propose the Performance Refinement and Evolution Model (PREM) as a performance management framework. Based on the specification of quantitative measurement and workloads, PREM classifies performance requirements specification, analysis activities, and testing into four levels. In this paper, we provide an overview of this model.},
booktitle = {Proceedings of the 6th International Workshop on Software and Performance},
pages = {133–136},
numpages = {4},
keywords = {software performance testing, software performance engineering process, performance requirements},
location = {Buenes Aires, Argentina},
series = {WOSP '07}
}

@inproceedings{heckman2006automated,
  title={Automated adaptive ranking and filtering of static analysis alerts},
  author={Heckman, Sarah and Williams, Laurie},
  booktitle={Proc of the Fast abstract at the International Symposium on Software Reliability Engineering (ISSRE)},
  year={2006},
  organization={Citeseer}
}

@inproceedings{gegick2006early,
  title={An early testing and defense web application framework for malicious input attacks},
  author={Gegick, Michael and Isakson, Eric and Williams, Laurie},
  booktitle={ISSRE Supplementary Conference Proceedings},
  year={2006},
  url={https://repository.lib.ncsu.edu/server/api/core/bitstreams/1efe15b1-2349-4db1-a830-1b5b03f0a650/content}
}

@article{zhengidentifying,
  title={Identifying Change in Dynamic Link Library COTS Components When Source Code is Not Available},
  author={Zheng, Jiang and Williams, Laurie and Robinson, Brian and Smiley, Karen},
  url={https://www.academia.edu/download/48034042/ISSRE06_Zheng_v2.pdf},
  year={2006}
}

@article{barnes2006stars,
  title={The STARS Alliance: Experiences in Broadening Participation in Computing},
  author={Barnes, T and Dahlberg, T},
  journal={Proc. Grace Hopper Celebration of Women in Computing (GHC2006)},
  pages={4--7},
  year={2006}
}

@inproceedings{sherriff2005method,
  title={A Method for Verification and Validation Certificate Management in Eclipse},
  author={Sherriff, Mark and Williams, Laurie},
  booktitle={Workshop on Software Certificate Management, Long Beach, CA},
  pages={19--22},
  year={2005},
  url={https://www.academia.edu/download/48033986/sc05-proceedings.pdf#page=27}
}

@inproceedings{strom2005good,
  title={The “Good Enough”’Reliability Tool (GERT)-Version 2},
  author={Strom, Michele and Davidson, Martin and Williams, Laurie and Vouk, Mladen},
  booktitle={Supplementary Proceedings of the 16th IEEE International Symposium on Software Reliability Engineering (ISSRE 2005), Chicago, Illinois},
  pages={8--11},
  year={2005},
  organization={Citeseer}
}

@inproceedings{sherriff2005certification,
  title={Certification of code during development to provide an estimate of defect density},
  author={Sherriff, Mark and Williams, Laurie},
  booktitle={Fast Abstract, International Symposium on Software Reliability Engineering, Chicago, IL},
  pages={447--448},
  year={2005},
  url={https://www.researchgate.net/profile/Mark-Sherriff/publication/228965904_Certification_of_Code_During_Development_to_Provide_an_Estimate_of_Defect_Density/links/0deec51a60ba3cc197000000/Certification-of-Code-During-Development-to-Provide-an-Estimate-of-Defect-Density.pdf}
}

@inproceedings{smith2005expediting,
  title={Expediting Programmer AWAREness of Anomalous Code},
  author={Smith, Sarah E and Williams, Laurie and Xu, Jun},
  booktitle={proceedings of International Symposium on Software Reliability Engineering (ISSRE'05), Chicago, IL},
  pages={4--49},
  year={2005}
}

@inproceedings{10.1145/1083200.1083211,
author = {Gegick, Michael and Williams, Laurie},
title = {Matching attack patterns to security vulnerabilities in software-intensive system designs},
year = {2005},
isbn = {1595931147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1083200.1083211},
doi = {10.1145/1083200.1083211},
abstract = {Fortifying software applications from attack is often an effort that occurs late in the software development process. Applying patches to fix vulnerable applications in the field is a common approach to securing applications. Abstract representations of attacks such as attack trees and attack nets can be used for identifying potential threats before a system is released. We have constructed attack patterns that can illuminate security vulnerabilities in a software-intensive system design. Matching our attack patterns to vulnerabilities in the design phase may stimulate security efforts to start early and to become integrated with the software process. The intent is that our attack patterns can be used to effectively encode software vulnerabilities in vulnerability databases. A case study of our approach with undergraduate students in a security course indicated that our attack patterns can provide general descriptions of vulnerabilities. The students were able to accurately map the patterns to vulnerabilities in a system design.},
booktitle = {Proceedings of the 2005 Workshop on Software Engineering for Secure Systems—Building Trustworthy Applications},
pages = {1–7},
numpages = {7},
keywords = {security, regular expression, design},
location = {St. Louis, Missouri},
series = {SESS '05}
}

@article{10.1145/1082983.1083211,
author = {Gegick, Michael and Williams, Laurie},
title = {Matching attack patterns to security vulnerabilities in software-intensive system designs},
year = {2005},
issue_date = {July 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/1082983.1083211},
doi = {10.1145/1082983.1083211},
abstract = {Fortifying software applications from attack is often an effort that occurs late in the software development process. Applying patches to fix vulnerable applications in the field is a common approach to securing applications. Abstract representations of attacks such as attack trees and attack nets can be used for identifying potential threats before a system is released. We have constructed attack patterns that can illuminate security vulnerabilities in a software-intensive system design. Matching our attack patterns to vulnerabilities in the design phase may stimulate security efforts to start early and to become integrated with the software process. The intent is that our attack patterns can be used to effectively encode software vulnerabilities in vulnerability databases. A case study of our approach with undergraduate students in a security course indicated that our attack patterns can provide general descriptions of vulnerabilities. The students were able to accurately map the patterns to vulnerabilities in a system design.},
journal = {SIGSOFT Softw. Eng. Notes},
month = may,
pages = {1–7},
numpages = {7},
keywords = {security, regular expression, design}
}

@article{10.1145/1082983.1083100,
author = {Srikanth, Hema and Williams, Laurie},
title = {On the economics of requirements-based test case prioritization},
year = {2005},
issue_date = {July 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/1082983.1083100},
doi = {10.1145/1082983.1083100},
abstract = {Software testing is a strenuous and expensive process. At least 50\% of the total software cost is spent on testing activities [12]. Companies are often faced with time and resource constraints that limit their ability to effectively complete testing efforts. Companies generally save suites for reuse; test suite reuse accounts for almost half of the maintenance cost [9]. As the product goes thru several versions, executing all the test cases in a test suite can be expensive [9]. Prioritization of test cases can be cost effective when the time allocated to complete testing is limited [9]. Test case prioritization (TCP) involves the explicit planning of the execution of test cases in a specific order and is shown to improve the rate of fault detection [3, 9]. The current software TCP techniques are primarily coverage-based (statement, branch or other coverage) [3,9]. Coverage-based white-box prioritization techniques are most applicable for regression testing at the unit level and are harder to apply on complex systems [2]. These techniques require testers to read and understand the code, which can be time consuming [2], and may assume that all faults are equally severe.},
journal = {SIGSOFT Softw. Eng. Notes},
month = may,
pages = {1–3},
numpages = {3}
}

@inproceedings{10.1145/1083091.1083100,
author = {Srikanth, Hema and Williams, Laurie},
title = {On the economics of requirements-based test case prioritization},
year = {2005},
isbn = {159593118X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1083091.1083100},
doi = {10.1145/1083091.1083100},
abstract = {Software testing is a strenuous and expensive process. At least 50\% of the total software cost is spent on testing activities [12]. Companies are often faced with time and resource constraints that limit their ability to effectively complete testing efforts. Companies generally save suites for reuse; test suite reuse accounts for almost half of the maintenance cost [9]. As the product goes thru several versions, executing all the test cases in a test suite can be expensive [9]. Prioritization of test cases can be cost effective when the time allocated to complete testing is limited [9]. Test case prioritization (TCP) involves the explicit planning of the execution of test cases in a specific order and is shown to improve the rate of fault detection [3, 9]. The current software TCP techniques are primarily coverage-based (statement, branch or other coverage) [3,9]. Coverage-based white-box prioritization techniques are most applicable for regression testing at the unit level and are harder to apply on complex systems [2]. These techniques require testers to read and understand the code, which can be time consuming [2], and may assume that all faults are equally severe.},
booktitle = {Proceedings of the Seventh International Workshop on Economics-Driven Software Engineering Research},
pages = {1–3},
numpages = {3},
location = {St. Louis, Missouri},
series = {EDSER '05}
}

@article{10.1145/1082983.1083304,
author = {Nagappan, Nachiappan and Williams, Laurie and Vouk, Mladen and Osborne, Jason},
title = {Early estimation of software quality using in-process testing metrics: a controlled case study},
year = {2005},
issue_date = {July 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/1082983.1083304},
doi = {10.1145/1082983.1083304},
abstract = {In industrial practice, information on post-release field quality of a product tends to become available too late in the software development process to affordably guide corrective actions. An important step towards remediation of this problem of late information lies in the ability to provide an early estimation of software post-release field quality. This paper presents the use of a suite of in-process metrics that leverages the software testing effort to provide (1) an estimation of potential software field quality in early software development phases, and (2) the identification of low quality software programs. A controlled case study conducted at North Carolina State University provides initial indication that our approach is effective for making an early assessment of post-release field quality.},
journal = {SIGSOFT Softw. Eng. Notes},
month = may,
pages = {1–7},
numpages = {7},
keywords = {testing metrics, software field quality, multiple regression, empirical software engineering}
}

@inproceedings{10.1145/1083292.1083304,
author = {Nagappan, Nachiappan and Williams, Laurie and Vouk, Mladen and Osborne, Jason},
title = {Early estimation of software quality using in-process testing metrics: a controlled case study},
year = {2005},
isbn = {1595931228},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1083292.1083304},
doi = {10.1145/1083292.1083304},
abstract = {In industrial practice, information on post-release field quality of a product tends to become available too late in the software development process to affordably guide corrective actions. An important step towards remediation of this problem of late information lies in the ability to provide an early estimation of software post-release field quality. This paper presents the use of a suite of in-process metrics that leverages the software testing effort to provide (1) an estimation of potential software field quality in early software development phases, and (2) the identification of low quality software programs. A controlled case study conducted at North Carolina State University provides initial indication that our approach is effective for making an early assessment of post-release field quality.},
booktitle = {Proceedings of the Third Workshop on Software Quality},
pages = {1–7},
numpages = {7},
keywords = {testing metrics, software field quality, multiple regression, empirical software engineering},
location = {St. Louis, Missouri},
series = {3-WoSQ}
}

@article{10.1145/1082983.1083285,
author = {Sherriff, Mark and Nagappan, Nachiappan and Williams, Laurie and Vouk, Mladen},
title = {Early estimation of defect density using an in-process Haskell metrics model},
year = {2005},
issue_date = {July 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/1082983.1083285},
doi = {10.1145/1082983.1083285},
abstract = {Early estimation of defect density of a product is an important step towards the remediation of the problem associated with affordably guiding corrective actions in the software development process. This paper presents a suite of in-process metrics that leverages the software testing effort to create a defect density prediction model for use throughout the software development process. A case study conducted with Galois Connections, Inc. in a Haskell programming environment indicates that the resulting defect density prediction is indicative of the actual system defect density.},
journal = {SIGSOFT Softw. Eng. Notes},
month = may,
pages = {1–6},
numpages = {6},
keywords = {software quality, multiple regression, haskell, empirical software engineering}
}

@inproceedings{10.1145/1083274.1083285,
author = {Sherriff, Mark and Nagappan, Nachiappan and Williams, Laurie and Vouk, Mladen},
title = {Early estimation of defect density using an in-process Haskell metrics model},
year = {2005},
isbn = {1595931155},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1083274.1083285},
doi = {10.1145/1083274.1083285},
abstract = {Early estimation of defect density of a product is an important step towards the remediation of the problem associated with affordably guiding corrective actions in the software development process. This paper presents a suite of in-process metrics that leverages the software testing effort to create a defect density prediction model for use throughout the software development process. A case study conducted with Galois Connections, Inc. in a Haskell programming environment indicates that the resulting defect density prediction is indicative of the actual system defect density.},
booktitle = {Proceedings of the 1st International Workshop on Advances in Model-Based Testing},
pages = {1–6},
numpages = {6},
keywords = {software quality, multiple regression, haskell, empirical software engineering},
location = {St. Louis, Missouri},
series = {A-MOST '05}
}

@inproceedings{10.1145/1082948.1082957,
author = {Zheng, Jiang and Robinson, Brian and Williams, Laurie and Smiley, Karen},
title = {A process for identifying changes when source code is not available},
year = {2005},
isbn = {1595931295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1082948.1082957},
doi = {10.1145/1082948.1082957},
abstract = {Various regression test selection techniques have been developed and shown to improve fault detection effectiveness. The majority of these test selection techniques rely on access to source code for change identification. However, when new releases of COTS components are made available for integration and testing, source code is often not available to guide regression test selection. This paper describes a process for identifying changed functions when code is not available. This change information is beneficial for selecting white-box regression tests of customer/glue code. This process is applicable when COTS licensing agreements do not preclude decompilation. A feasibility study of the process was conducted with four releases of a medium-scale internal ABB product. The results of the feasibility study indicate that this process can be effective in identifying changed functions.},
booktitle = {Proceedings of the Second International Workshop on Models and Processes for the Evaluation of Off-the-Shelf Components},
pages = {1–4},
numpages = {4},
keywords = {COTS, change identification},
location = {St. Louis, Missouri},
series = {MPEC '05}
}

@article{10.1145/1082983.1082957,
author = {Zheng, Jiang and Robinson, Brian and Williams, Laurie and Smiley, Karen},
title = {A process for identifying changes when source code is not available},
year = {2005},
issue_date = {July 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/1082983.1082957},
doi = {10.1145/1082983.1082957},
abstract = {Various regression test selection techniques have been developed and shown to improve fault detection effectiveness. The majority of these test selection techniques rely on access to source code for change identification. However, when new releases of COTS components are made available for integration and testing, source code is often not available to guide regression test selection. This paper describes a process for identifying changed functions when code is not available. This change information is beneficial for selecting white-box regression tests of customer/glue code. This process is applicable when COTS licensing agreements do not preclude decompilation. A feasibility study of the process was conducted with four releases of a medium-scale internal ABB product. The results of the feasibility study indicate that this process can be effective in identifying changed functions.},
journal = {SIGSOFT Softw. Eng. Notes},
month = may,
pages = {1–4},
numpages = {4},
keywords = {COTS, change identification}
}

@inproceedings{10.1145/1083174.1083179,
author = {Williams, Laurie and Layman, Lucas and Abrahamsson, Pekka},
title = {On establishing the essential components of a technology-dependent framework: a strawman framework for industrial case study-based research},
year = {2005},
isbn = {159593121X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1083174.1083179},
doi = {10.1145/1083174.1083179},
abstract = {A goal of evidence-based software engineering is to provide a means by which industry practitioners can make rational decisions about technology adoption. When a technology is mature enough for potential widespread use, practitioners find empirical evidence most compelling when the study has taken place in a live, industrial situation in an environment comparable to their own. However, empirical software engineering is in need of guidelines and standards to direct industrial case studies so that the results of this research are valuable and can be combined into an evidentiary base. In this paper, we present a high-level view of a measurement framework that has been used with multiple agile software development industrial case studies. We propose that this technology-dependent framework can be used as a strawman for a guideline of data collection, analysis, and reporting of industrial case studies. Our goal in offering the framework as a strawman is to solicit input from the community on a guideline for the essential components of a technology-dependent framework for industrial case study research.},
booktitle = {Proceedings of the 2005 Workshop on Realising Evidence-Based Software Engineering},
pages = {1–5},
numpages = {5},
location = {St. Louis, Missouri},
series = {REBSE '05}
}

@article{10.1145/1082983.1083179,
author = {Williams, Laurie and Layman, Lucas and Abrahamsson, Pekka},
title = {On establishing the essential components of a technology-dependent framework: a strawman framework for industrial case study-based research},
year = {2005},
issue_date = {July 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/1082983.1083179},
doi = {10.1145/1082983.1083179},
abstract = {A goal of evidence-based software engineering is to provide a means by which industry practitioners can make rational decisions about technology adoption. When a technology is mature enough for potential widespread use, practitioners find empirical evidence most compelling when the study has taken place in a live, industrial situation in an environment comparable to their own. However, empirical software engineering is in need of guidelines and standards to direct industrial case studies so that the results of this research are valuable and can be combined into an evidentiary base. In this paper, we present a high-level view of a measurement framework that has been used with multiple agile software development industrial case studies. We propose that this technology-dependent framework can be used as a strawman for a guideline of data collection, analysis, and reporting of industrial case studies. Our goal in offering the framework as a strawman is to solicit input from the community on a guideline for the essential components of a technology-dependent framework for industrial case study research.},
journal = {SIGSOFT Softw. Eng. Notes},
month = may,
pages = {1–5},
numpages = {5}
}

@inproceedings{berenson2005examining,
  title={Examining time as a factor in young women’s IT career decisions},
  author={Berenson, S and Williams, L and Michael, J and Vouk, M},
  booktitle={Proceedings of the Crossing Cultures, Changing Lives International Research Conference},
  year={2005}
}

@INPROCEEDINGS{4698929,
  author={Williams, Laurie and Smith, Sarah E. and Rappa, Michael},
  booktitle={18th Conference on Software Engineering Education & Training (CSEET'05)}, 
  title={Resources for Agile Software Development in the Software Engineering Course}, 
  year={2005},
  volume={},
  number={},
  pages={236-238},
  keywords={Software engineering;Programming profession;Automatic testing;Courseware;Project management;Monopoly;Collaboration;Dynamic programming;Seminars;Databases},
  doi={10.1109/CSEET.2005.26},
  url={https://ieeexplore.ieee.org/abstract/document/4698929/}
}

@inproceedings{10.1145/1151433.1151436,
author = {Layman, Lucas and Williams, Laurie and Cunningham, Lynn},
title = {Motivations and measurements in an agile case study},
year = {2004},
isbn = {9781450378185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1151433.1151436},
doi = {10.1145/1151433.1151436},
abstract = {With the recent emergence of agile software development technologies, the software community is awaiting sound, empirical investigation of the impacts of agile practices in a live setting. One means of conducting such research is through industrial case studies. However, there are a number of influencing factors that contribute to the success of such a case study. In this paper, we describe a case study performed at Sabre Airline Solutions evaluating the effects of adopting Extreme Programming (XP) practices with a team that had characteristically plan-driven risk factors. We compare the team's business-related results (productivity and quality) to two published sources of industry averages. Our case study found that the Sabre team yielded above-average post-release quality and average to above-average productivity. We discuss our experience in conducting this case study, including specifics of how data was collected, the rationale behind our process of data collection, and what obstacles were encountered during the case study. We also identify four factors that potentially impact the outcome of industrial case studies: availability of data, tool support, co-operative personnel and project status. We believe that recognizing and planning for these factors is essential to conducting industrial case studies, and that this information will be helpful to researchers and practitioners alike.},
booktitle = {Proceedings of the 2004 Workshop on Quantitative Techniques for Software Agile Process},
pages = {14–24},
numpages = {11},
keywords = {agile software development, case studies, extreme programming},
location = {Newport Beach, California},
series = {QUTE-SWAP '04}
}

@inproceedings{10.1145/1066129.1066144,
author = {Ho, Chih-Wei and Raha, Somik and Gehringer, Edward and Williams, Laurie},
title = {Sangam: a distributed pair programming plug-in for Eclipse},
year = {2004},
isbn = {9781450377980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1066129.1066144},
doi = {10.1145/1066129.1066144},
abstract = {In pair programming, two programmers traditionally work side-by-side at one computer. However, in globally distributed organizations, long-distance collaboration is frequently necessary. Sangam is an Eclipse plug-in that allows Eclipse users in different locations to share a workspace so that they may work as if they were using the same computer. In this paper, we discuss the Sangam plug-in, and our experience developing it via distributed and collocated pair programming.},
booktitle = {Proceedings of the 2004 OOPSLA Workshop on Eclipse Technology EXchange},
pages = {73–77},
numpages = {5},
location = {Vancouver, British Columbia, Canada},
series = {eclipse '04}
}

@inproceedings{sherriff2004using,
  title={Using in-process metrics to predict defect density in haskell programs},
  author={Sherriff, Mark and Williams, Laurie and Vouk, Mladen},
  booktitle={Fast Abstract, International Symposium on Software Reliability Engineering, St. Malo, France},
  year={2004},
  url={https://www.academia.edu/download/30793445/ISSRE-FA-SWV04.pdf}
}

@inproceedings{nagappan2004using,
  title={Using In-Process Testing Metrics to Estimate Software Reliability: A Feasibility Study},
  author={Nagappan, Nachiappan and Williams, Laurie and Vouk, Mladen and Osborne, Jason},
  booktitle={Proceedings of IEEE International Symposium on Software Reliability Engineering, FastAbstract, Saint Malo, France},
  pages={21--22},
  year={2004},
  url={https://www.academia.edu/download/48034004/ISSRE_STREW-J.pdf}
}

@article{10.1145/1022494.1022546,
author = {Williams, Laurie},
title = {On the need for a process for making reliable quality comparisons with industrial data},
year = {2004},
issue_date = {September 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/1022494.1022546},
doi = {10.1145/1022494.1022546},
abstract = {Many factors influence quality data obtained from industrial case studies making comparisons difficult. In this paper, two longitudinal industrial case study experiences are shared which illustrate the complications that can arise. The first is a case study of an IBM team that transitioned to the use of test-driven development. The primary quality measure was functional verification test defects normalized by lines of code. The second case study was performed with an Extreme Programming team at Sabre Airline Solutions. Both test defects and field defects were compared. In both case studies, differences existed which made the comparisons indicative but not absolute.},
journal = {SIGSOFT Softw. Eng. Notes},
month = sep,
pages = {1–4},
numpages = {4}
}

@INPROCEEDINGS{1408595,
  author={Ho, C. and Slaten, K. and Williams, L. and Berenson, S.},
  booktitle={34th Annual Frontiers in Education, 2004. FIE 2004.}, 
  title={Work in progress-unexpected student outcome from collaborative agile software development practices and paired programming in a software engineering course}, 
  year={2004},
  volume={},
  number={},
  pages={F2C-15},
  keywords={Collaborative software;Collaborative work;Software engineering;Programming profession;Computer science;Educational programs;Computer science education;Mathematical programming;Data analysis;Information technology},
  doi={10.1109/FIE.2004.1408595},
  url={https://ieeexplore.ieee.org/abstract/document/1408595/}
}

@inproceedings{10.1145/965660.965667,
author = {Nagappan, Nachiappan and Williams, Laurie and Vouk, Mladen},
title = {"Good enough" software reliability estimation plug-in for Eclipse},
year = {2003},
isbn = {9781450374705},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/965660.965667},
doi = {10.1145/965660.965667},
abstract = {Programmers who use the test-driven development practice of the Extreme Programming methodology write extensive automated unit and acceptance tests. This paper describes an Eclipse plug-in that utilizes the results of this automated testing, and in combination with a suite of internal product metrics, provides an early assessment of product reliability. We discuss the correlation between the metrics we use and the reliability of the developed software, as well as the general functional characteristics of the alpha version of our Eclipse plug-in.},
booktitle = {Proceedings of the 2003 OOPSLA Workshop on Eclipse Technology EXchange},
pages = {30–34},
numpages = {5},
location = {Anaheim, California},
series = {eclipse '03}
}

@inproceedings{williams2002good,
  title={“Good Enough” Reliability for Extreme Programming},
  author={Williams, Laurie and Wang, Lili and Vouk, Mladen},
  booktitle={presented at Fast Abstract, International Symposium on Software Reliability Engineering},
  year={2002},
  organization={Citeseer}
}

@inproceedings{gehringer2002exploring,
  title={Exploring pair programming in distributed object-oriented team projects},
  author={Gehringer, Ed},
  booktitle={Educator's Workshop, OOPSLA},
  year={2002},
  url={https://www.academia.edu/download/86169152/EdSym_DistPP_FinalSubmission.pdf}
}

@inproceedings{williams2002pair,
  title={Pair programming in an introductory computer science course: Initial results and recommendations},
  author={Williams, Laurie and Yang, Kai and Wiebe, Eric and Ferzli, Miriam and Miller, Carol},
  booktitle={OOPSLA Educator's Symposium, Seattle, WA},
  year={2002},
  url={https://www.researchgate.net/profile/Carol-Miller-16/publication/242418612_Pair_Programming_in_an_Introductory_Computer_Science_Course_Initial_Results_and_Recommendations/links/5432b9fc0cf20c6211bc6dfe/Pair-Programming-in-an-Introductory-Computer-Science-Course-Initial-Results-and-Recommendations.pdf}
}

@inproceedings{williams2002economic,
  title={On the economic feasibility of pair programming},
  author={Williams, Laurie and Erdogmus, Hakan},
  booktitle={International Workshop on Economics-Driven Software Engineering Research EDSER},
  volume={4},
  year={2002}
}

@inproceedings{williamsalternative,
  title={An Alternative: The Collaborative Software Process (CSP)},
  author={Williams, Laurie},
  booktitle={Workshop on Teaching PSP and TSPi in Universities},
  pages={19--21},
  organization={Citeseer}
}


@inproceedings{fraser2000hacker,
  title={Hacker or hero?-extreme programming today (panel session)},
  author={Fraser, Steven and Beck, Kent and Cunningham, Ward and Crocker, Ron and Fowler, Martin and Rising, Linda and Williams, Laurie},
  booktitle={Addendum to the 2000 proceedings of the conference on Object-oriented programming, systems, languages, and applications (Addendum)},
  pages={5--7},
  year={2000},
  url={https://dl.acm.org/doi/pdf/10.1145/367845.367892}
}

@INPROCEEDINGS{841619,
  author={Williams, L.},
  booktitle={FIE'99 Frontiers in Education. 29th Annual Frontiers in Education Conference. Designing the Future of Science and Engineering Education. Conference Proceedings (IEEE Cat. No.99CH37011}, 
  title={But, isn't that cheating? [collaborative programming]}, 
  year={1999},
  volume={2},
  number={},
  pages={12B9/26-12B9/27 vol.2},
  keywords={Programming profession;Collaborative work;Testing;Computer science;Problem-solving;Cities and towns;Algorithm design and analysis;Performance evaluation;Mice;Keyboards},
  doi={10.1109/FIE.1999.841619},
  url={https://ieeexplore.ieee.org/abstract/document/841619/}
}
