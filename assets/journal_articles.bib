@article{williams2025research,
	title         = {Research Directions in Software Supply Chain Security},
	author        = {Williams, Laurie and Benedetti, Giacomo and Hamer, Sivana and Paramitha, Ranindya and Rahman, Imranur and Tamanna, Mahzabin and Tystahl, Greg and Zahan, Nusrat and Morrison, Patrick and Acar, Yasemin and Cukier, Michel and K\"{a}stner, Christian and Kapravelos, Alexandros and Wermke, Dominik and Enck, William},
	year          = {2025},
	month         = may,
	journal       = {ACM Trans. Softw. Eng. Methodol.},
	publisher     = {Association for Computing Machinery},
	address       = {New York, NY, USA},
	volume        = {34},
	number        = {5},
	doi           = {10.1145/3714464},
	issn          = {1049-331X},
	url           = {https://doi.org/10.1145/3714464},
	issue_date    = {June 2025},
	articleno     = {146},
	numpages      = {38},
	keywords      = {Software security, Software supply chain security, Open source security},
}

@article{10.1007/s10664-025-10621-5,
author = {Seth, Aishwarya and Bhattacharya, Saikath and Elder, Sarah and Zahan, Nusrat and Williams, Laurie},
title = {Comparing effectiveness and efficiency of Interactive Application Security Testing (IAST) and Runtime Application Self-Protection (RASP) tools in a large java-based system},
year = {2025},
issue_date = {Feb 2025},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {30},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-025-10621-5},
doi = {10.1007/s10664-025-10621-5},
journal = {Empirical Softw. Engg.},
month = feb,
numpages = {27},
keywords = {Vulnerability management, Web application security, Security analysis tools, Vulnerability scanners, Interactive application security testing, Runtime application self-protection}
}

@article{10.1145/3648610,
author = {Elder, Sarah and Rahman, Md Rayhanur and Fringer, Gage and Kapoor, Kunal and Williams, Laurie},
title = {A Survey on Software Vulnerability Exploitability Assessment},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {8},
issn = {0360-0300},
url = {https://doi.org/10.1145/3648610},
doi = {10.1145/3648610},
abstract = {Knowing the exploitability and severity of software vulnerabilities helps practitioners prioritize vulnerability mitigation efforts. Researchers have proposed and evaluated many different exploitability assessment methods. The goal of this research is to assist practitioners and researchers in understanding existing methods for assessing vulnerability exploitability through a survey of exploitability assessment literature. We identify three exploitability assessment approaches: assessments based on original, manual Common Vulnerability Scoring System, automated Deterministic assessments, and automated Probabilistic assessments. Other than the original Common Vulnerability Scoring System, the two most common sub-categories are Deterministic, Program State based, and Probabilistic learning model assessments.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {205},
numpages = {41},
keywords = {Exploitability, software vulnerability}
}

@article{10.1145/3672555,
author = {Mahdavi-Hezaveh, Rezvan and Fatima, Sameeha and Williams, Laurie},
title = {Paving a Path for a Combined Family of Feature Toggle and Configuration Option Research},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {7},
issn = {1049-331X},
url = {https://doi.org/10.1145/3672555},
doi = {10.1145/3672555},
abstract = {Feature toggles and configuration options are techniques to include or exclude functionality in software. The research contributions to these two techniques have most often been focused on either one of them. However, focusing on the similarities of these two techniques and the use of a common terminology may enable a combined family of research on software configuration (a term we use to encompass both techniques) and prevent duplication of effort. The goal of this study is to aid researchers in conducting a family of research on software configuration by extending an existing model of software configuration that provides a common terminology for feature toggles and configuration options in research studies. We started with Siegmund et al.’s Model of Software Configuration (MSC), which was developed based on configuration option-related resources. We extend the MSC by qualitative analysis of feature toggle-related resources. From our analysis, we proposed MSCv2 and evaluated it through its application on publications and an industrial system. Our results indicate researchers studying the same system may provide different definitions of software configuration in publications, similar research questions may be answered repeatedly because of a lack of a clear definition of software configuration, and having an MSC may enable generalized research on this family of research.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {172},
numpages = {27},
keywords = {Feature toggle, configuration option, software configuration, software engineering}
}

@article{10.1109/TSE.2023.3319509,
author = {Imtiaz, Nasif and Williams, Laurie},
title = {Are Your Dependencies Code Reviewed?: Measuring Code Review Coverage in Dependency Updates},
year = {2023},
issue_date = {Nov. 2023},
publisher = {IEEE Press},
volume = {49},
number = {11},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2023.3319509},
doi = {10.1109/TSE.2023.3319509},
abstract = {As modern software extensively uses free open source packages as dependencies, developers have to regularly pull in new third-party code through frequent updates. However, without a proper review of every incoming change, vulnerable and malicious code can sneak into the codebase through these dependencies. The goal of this study is to aid developers in securely accepting dependency updates by measuring if the code changes in an update have passed through a code review process. We implement Depdive, an update audit tool for packages in Crates.io, npm, PyPI, and RubyGems registry. Depdive first (i) identifies the files and the code changes in an update that cannot be traced back to the package's source repository, i.e., <italic>phantom artifacts</italic>; and then (ii) measures what portion of changes in the update, excluding the phantom artifacts, has passed through a code review process, i.e., <italic>code review coverage</italic>. Using Depdive, we present an empirical study across the latest ten updates of the most downloaded 1000 packages in each of the four registries. We further evaluated our results through a maintainer agreement survey. We find that phantom artifacts are not uncommon in the updates (20.1\% of the analyzed updates had at least one phantom file). The phantoms can appear either due to legitimate reasons, such as in the case of programmatically generated files, or from accidental inclusion, such as in the case of files that are ignored in the repository. Regarding code review coverage (<italic>CRC</italic>), we find the updates are typically only partially code-reviewed (52.5\% of the time). Further, only 9.0\% of the packages had all their updates in our data set fully code-reviewed, indicating that even the most used packages can introduce non-reviewed code in the software supply chain. We also observe that updates either tend to have high <italic>CRC</italic> or low <italic>CRC</italic>, suggesting that packages at the opposite end of the spectrum may require a separate set of treatments.},
journal = {IEEE Trans. Softw. Eng.},
month = nov,
pages = {4932–4945},
numpages = {14}
}

@ARTICLE{10163720,
  author={Zahan, Nusrat and Kanakiya, Parth and Hambleton, Brian and Shohan, Shohanuzzaman and Williams, Laurie},
  journal={IEEE Security & Privacy}, 
  title={OpenSSF Scorecard: On the Path Toward Ecosystem-Wide Automated Security Metrics}, 
  year={2023},
  volume={21},
  number={6},
  pages={76-88},
  keywords={Security;Software measurement;Software development management;Open source software;Ecosystems;Task analysis;Standards},
  doi={10.1109/MSEC.2023.3279773}
}

@article{10.1145/3571726,
author = {Rahman, Md Rayhanur and Hezaveh, Rezvan Mahdavi and Williams, Laurie},
title = {What Are the Attackers Doing Now? Automating Cyberthreat Intelligence Extraction from Text on Pace with the Changing Threat Landscape: A Survey},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {12},
issn = {0360-0300},
url = {https://doi.org/10.1145/3571726},
doi = {10.1145/3571726},
abstract = {Cybersecurity researchers have contributed to the automated extraction of CTI from textual sources, such as threat reports and online articles describing cyberattack strategies, procedures, and tools. The goal of this article is to aid cybersecurity researchers in understanding the current techniques used for cyberthreat intelligence extraction from text through a survey of relevant studies in the literature. Our work finds 11 types of extraction purposes and 7 types of textual sources for CTI extraction. We observe the technical challenges associated with obtaining available clean and labeled data for replication, validation, and further extension of the studies. We advocate for building upon the current CTI extraction work to help cybersecurity practitioners with proactive decision-making such as in threat prioritization and mitigation strategy formulation to utilize knowledge from past cybersecurity incidents.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {241},
numpages = {36},
keywords = {Cyberthreat intelligence, CTI extraction, CTI mining, IoC extraction, TTPs extraction, attack pattern extraction, threat reports, tactical threat intelligence, technical threat intelligence}
}

@ARTICLE{9792380,
  author={Imtiaz, Nasif and Khanom, Aniqa and Williams, Laurie},
  journal={IEEE Transactions on Software Engineering}, 
  title={Open or Sneaky? Fast or Slow? Light or Heavy?: Investigating Security Releases of Open Source Packages}, 
  year={2023},
  volume={49},
  number={4},
  pages={1540-1560},
  keywords={Security;Codes;Delays;Ecosystems;Databases;Semantics;Supply chains;Empirical study;open source security;supply chain security},
  doi={10.1109/TSE.2022.3181010}
}

@article{10.1007/s10664-022-10179-6,
author = {Elder, Sarah and Zahan, Nusrat and Shu, Rui and Metro, Monica and Kozarev, Valeri and Menzies, Tim and Williams, Laurie},
title = {Do I really need all this work to find vulnerabilities? An empirical case study comparing vulnerability detection techniques on a Java application},
year = {2022},
issue_date = {Nov 2022},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-022-10179-6},
doi = {10.1007/s10664-022-10179-6},
journal = {Empirical Softw. Engg.},
month = nov,
numpages = {78},
keywords = {Vulnerability Scanners, Penetration Testing, Web Application Security, Vulnerability Management}
}

@ARTICLE{9732894,
author={Weir, Charles and Migues, Sammy and Williams, Laurie},
journal={ IEEE Security \& Privacy },
title={Exploring the Shift in Security Responsibility},
year={2022},
volume={20},
number={06},
ISSN={1558-4046},
pages={8-17},
abstract={ The Building Security in Maturity Model survey has been tracking software security activity adoption in 211 companies over 12 years. This article explores how organizations should adapt to the latest security challenges. },
keywords={Security;Statistics;Companies;Tracking;Data models;Software measurement},
doi={10.1109/MSEC.2022.3150238},
url = {https://doi.ieeecomputersociety.org/10.1109/MSEC.2022.3150238},
publisher={IEEE Computer Society},
address={Los Alamitos, CA, USA},
month=nov}

@article{10.1016/j.infsof.2021.106813,
author = {Mahdavi-Hezaveh, Rezvan and Ajmeri, Nirav and Williams, Laurie},
title = {Feature toggles as code: Heuristics and metrics for structuring feature toggles},
year = {2022},
issue_date = {May 2022},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {145},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106813},
doi = {10.1016/j.infsof.2021.106813},
journal = {Inf. Softw. Technol.},
month = may,
numpages = {14},
keywords = {Metric, Heuristic, Open source repository, Continuous development, Continuous integration, Feature toggle}
}

@article{10.1007/s10664-021-10109-y,
author = {Rahman, Md Rayhanur and Imtiaz, Nasif and Storey, Margaret-Anne and Williams, Laurie},
title = {Why secret detection tools are not enough: It’s not just about false positives - An industrial case study},
year = {2022},
issue_date = {May 2022},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-10109-y},
doi = {10.1007/s10664-021-10109-y},
abstract = {Checked-in secrets in version-controlled software projects pose security risks to software and services. Secret detection tools can identify the presence of secrets in the code, commit changesets, and project version control history. As these tools can generate false positives, developers are provided with mechanisms to bypass the warnings generated from these tools. Providing this override mechanism can result in developers sometimes exposing secrets in software repositories. The goal of this article is to aid software security practitioners in understanding why‘ secrets are checked into repositories, despite being warned by tools, through an industrial case study of analysis of usage data of a secret detection tool and a survey of developers who bypassed the tool alert. In this case study, we analyzed the usage data of a checked-in secret detection tool used widely by a software company and we surveyed developers who bypassed the warnings generated by the tool. From the case study, we found that, despite developers classified 50\% of the warning as false positive, developers also bypassed the warning due to time constraints, working with non-shipping projects, technical challenges of eliminating secrets completely from the version control history, technical debts, and perceptions that check-ins are low risk. We advocate practitioners and researchers to investigate the findings of our study further to improve secret detection tools and related development practices. We also advocate that organizations should insert secondary checks, as is done by the company we studied, to capture occasions where developers incorrectly bypass secret detection tools.},
journal = {Empirical Softw. Engg.},
month = may,
numpages = {29},
keywords = {Secret detection tool, Hardcoded secrets, Secrets in repositories, Credentials in repositories}
}

@article{shu2022omni,
  title={Omni: Automated ensemble with unexpected models against adversarial evasion attack},
  author={Shu, Rui and Xia, Tianpei and Williams, Laurie and Menzies, Tim},
  journal={Empirical Software Engineering},
  volume={27},
  number={1},
  pages={26},
  year={2022},
  publisher={Springer}
}

@article{rahman2021different,
  title={Different kind of smells: Security smells in infrastructure as code scripts},
  author={Rahman, Akond and Williams, Laurie},
  journal={IEEE Security \& Privacy},
  volume={19},
  number={3},
  pages={33--41},
  year={2021},
  publisher={IEEE}
}

@article{shu2021better,
  title={How to better distinguish security bug reports (using dual hyperparameter optimization)},
  author={Shu, Rui and Xia, Tianpei and Chen, Jianfeng and Williams, Laurie and Menzies, Tim},
  journal={Empirical Software Engineering},
  volume={26},
  number={3},
  pages={53},
  year={2021},
  publisher={Springer}
}

@article{mahdavi2021software,
  title={Software development with feature toggles: practices used by practitioners},
  author={Mahdavi-Hezaveh, Rezvan and Dremann, Jacob and Williams, Laurie},
  journal={Empirical Software Engineering},
  volume={26},
  number={1},
  pages={1},
  year={2021},
  publisher={Springer}
}

@article{10.1145/3408897,
author = {Rahman, Akond and Rahman, Md Rayhanur and Parnin, Chris and Williams, Laurie},
title = {Security Smells in Ansible and Chef Scripts: A Replication Study},
year = {2021},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3408897},
doi = {10.1145/3408897},
abstract = {Context: Security smells are recurring coding patterns that are indicative of security weakness and require further inspection. As infrastructure as code (IaC) scripts, such as Ansible and Chef scripts, are used to provision cloud-based servers and systems at scale, security smells in IaC scripts could be used to enable malicious users to exploit vulnerabilities in the provisioned systems. Goal: The goal of this article is to help practitioners avoid insecure coding practices while developing infrastructure as code scripts through an empirical study of security smells in Ansible and Chef scripts. Methodology: We conduct a replication study where we apply qualitative analysis with 1,956 IaC scripts to identify security smells for IaC scripts written in two languages: Ansible and Chef. We construct a static analysis tool called Security Linter for Ansible and Chef scripts (SLAC) to automatically identify security smells in 50,323 scripts collected from 813 open source software repositories. We also submit bug reports for 1,000 randomly selected smell occurrences. Results: We identify two security smells not reported in prior work: missing default in case statement and no integrity check. By applying SLAC we identify 46,600 occurrences of security smells that include 7,849 hard-coded passwords. We observe agreement for 65 of the responded 94 bug reports, which suggests the relevance of security smells for Ansible and Chef scripts amongst practitioners. Conclusion: We observe security smells to be prevalent in Ansible and Chef scripts, similarly to that of the Puppet scripts. We recommend practitioners to rigorously inspect the presence of the identified security smells in Ansible and Chef scripts using (i) code review, and (ii) static analysis tools.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
articleno = {3},
numpages = {31},
keywords = {Ansible, chef, configuration as code, configuration scripts, devops, devsecops, empirical study, infrastructure as code, insecure coding, security, smell, static analysis}
}

@ARTICLE{8883076,
  author={Yu, Zhe and Theisen, Christopher and Williams, Laurie and Menzies, Tim},
  journal={IEEE Transactions on Software Engineering}, 
  title={Improving Vulnerability Inspection Efficiency Using Active Learning}, 
  year={2021},
  volume={47},
  number={11},
  pages={2401-2420},
  keywords={Inspection;Software;Tools;Security;Predictive models;Error correction;NIST;Active learning;security;vulnerabilities;software engineering;error correction},
  doi={10.1109/TSE.2019.2949275}  
}

@article{10.1007/s10664-020-09841-8,
author = {Rahman, Akond and Farhana, Effat and Williams, Laurie},
title = {The ‘as code’ activities: development anti-patterns for infrastructure as code},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09841-8},
doi = {10.1007/s10664-020-09841-8},
journal = {Empirical Softw. Engg.},
month = sep,
pages = {3430–3467},
numpages = {38},
keywords = {Anti-pattern, Bugs, Configuration script, Continuous deployment, Defect, Devops, Infrastructure as code, Practice, Puppet, Quality}
}

@article{theisen2020better,
  title={Better together: Comparing vulnerability prediction models},
  author={Theisen, Christopher and Williams, Laurie},
  journal={Information and Software Technology},
  volume={119},
  pages={106204},
  year={2020},
  publisher={Elsevier}
}

@article{guo2020ccorba,
  title={{\c{C}}orba: Crowdsourcing to obtain requirements from regulations and breaches},
  author={Guo, Hui and Kafal{\i}, {\"O}zg{\"u}r and Jeukeng, Anne-Liz and Williams, Laurie and Singh, Munindar P},
  journal={Empirical Software Engineering},
  volume={25},
  number={1},
  pages={532--561},
  year={2020},
  publisher={Springer}
}

@article{rahman2019source,
  title={Source code properties of defective infrastructure as code scripts},
  author={Rahman, Akond and Williams, Laurie},
  journal={Information and Software Technology},
  volume={112},
  pages={148--163},
  year={2019},
  publisher={Elsevier}
}

@article{tondel2019collaborative,
  title={Collaborative security risk estimation in agile software development},
  author={T{\o}ndel, Inger Anne and Jaatun, Martin Gilje and Cruzes, Daniela Soares and Williams, Laurie},
  journal={Information \& Computer Security},
  volume={27},
  number={4},
  pages={508--535},
  year={2019},
  publisher={Emerald Publishing Limited}
}

@article{rahman2019systematic,
  title={A systematic mapping study of infrastructure as code research},
  author={Rahman, Akond and Mahdavi-Hezaveh, Rezvan and Williams, Laurie},
  journal={Information and Software Technology},
  volume={108},
  pages={65--77},
  year={2019},
  publisher={Elsevier}
}

@article{theisen2018attack,
  title={Attack surface definitions: A systematic literature review},
  author={Theisen, Christopher and Munaiah, Nuthan and Al-Zyoud, Mahran and Carver, Jeffrey C and Meneely, Andrew and Williams, Laurie},
  journal={Information and Software Technology},
  volume={104},
  pages={94--103},
  year={2018},
  publisher={Elsevier}
}

@article{morrison2018mapping,
  title={Mapping the field of software life cycle security metrics},
  author={Morrison, Patrick and Moye, David and Pandita, Rahul and Williams, Laurie},
  journal={Information and Software Technology},
  volume={102},
  pages={146--159},
  year={2018},
  publisher={Elsevier}
}

@article{williams2018engineering,
  title={Engineering security vulnerability prevention, detection, and response},
  author={Williams, Laurie and McGraw, Gary and Migues, Sammy},
  journal={IEEE Software},
  volume={35},
  number={5},
  pages={76--80},
  year={2018},
  publisher={IEEE}
}

@article{pandita2017tmap,
  title={Tmap: Discovering relevant api methods through text mining of api documentation},
  author={Pandita, Rahul and Jetley, Raoul and Sudarsan, Sithu and Menzies, Timothy and Williams, Laurie},
  journal={Journal of Software: Evolution and Process},
  volume={29},
  number={12},
  pages={e1845},
  year={2017},
  publisher={Wiley Online Library}
}

@inproceedings{10.1145/3180155.3182553,
author = {Morrison, Patrick J. and Pandita, Rahul and Xiao, Xusheng and Chillarege, Ram and Williams, Laurie},
title = {Are vulnerabilities discovered and resolved like other defects?},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3182553},
doi = {10.1145/3180155.3182553},
abstract = {Context: Software defect data has long been used to drive software development process improvement. If security defects (i.e.,vulnerabilities) are discovered and resolved by different software development practices than non-security defects, the knowledge of that distinction could be applied to drive process improvement.Objective: The goal of this research is to support technical leaders in making security-specific software development process improvements by analyzing the differences between the discovery and resolution of defects versus that of vulnerabilities.Method: We extend Orthogonal Defect Classification (ODC) [1], a scheme for classifying software defects to support software development process improvement, to study process-related differences between vulnerabilities and defects, creating ODC + Vulnerabilities (ODC+V). We applied ODC+V to classify 583 vulnerabilities and 583 defects across 133 releases of three open-source projects (Firefox, phpMyAdmin, and Chrome).Results: Compared with defects, vulnerabilities are found later in the development cycle and are more likely to be resolved through changes to conditional logic. In Firefox, vulnerabilities are resolved 33\% more quickly than defects. From a process improvement perspective, these results indicate opportunities may exist for more efficient vulnerability detection and resolution.Figures 1 and 2 present the percentage of defects and vulnerabilities found in each Activity for Firefox and phpMyAdmin, ordered from left to right as a timeline, first by pre-release, then by postrelease. In these projects, pre-release effort in vulnerability and defect detection correlates with pre-release vulnerability and defect resolution.Conclusion: We found ODC+V's property of associating vulnerability and defect discovery and resolution events with their software development process contexts helpful for gaining insight into three open source software projects. The addition of the Securitylmpact attribute, in particular, brought visibility into when threat types are discovered during the development process. We would expect use of ODC+V (and of base ODC) periodically over time to be helpful for steering software development projects toward their quality assurance goals.We give our full report in Morrison et al. [2] 1},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {498},
numpages = {1},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{riaz2017identifying,
  title={Identifying the implied: Findings from three differentiated replications on the use of security requirements templates},
  author={Riaz, Maria and King, Jason and Slankas, John and Williams, Laurie and Massacci, Fabio and Quesada-L{\'o}pez, Christian and Jenkins, Marcelo},
  journal={Empirical software engineering},
  volume={22},
  number={4},
  pages={2127--2178},
  year={2017},
  publisher={Springer}
}

@article{king2017log,
  title={To log, or not to log: using heuristics to identify mandatory log events--a controlled experiment},
  author={King, Jason and Stallings, Jon and Riaz, Maria and Williams, Laurie},
  journal={Empirical Software Engineering},
  volume={22},
  number={5},
  pages={2684--2717},
  year={2017},
  publisher={Springer}
}

@ARTICLE{7927896,
  author={Parnin, Chris and Helms, Eric and Atlee, Chris and Boughton, Harley and Ghattas, Mark and Glover, Andy and Holman, James and Micco, John and Murphy, Brendan and Savor, Tony and Stumm, Michael and Whitaker, Shari and Williams, Laurie},
  journal={IEEE Software}, 
  title={The Top 10 Adages in Continuous Deployment}, 
  year={2017},
  volume={34},
  number={3},
  pages={86-95},
  keywords={Software testing;Telemetry;Software engineering;Software development;Software measurement;continuous deployment;rapid release;telemetry;software engineering;software development},
  doi={10.1109/MS.2017.86}
}

@article{hibshi2016grounded,
  title={A grounded analysis of experts’ decision-making during security assessments},
  author={Hibshi, Hanan and Breaux, Travis D and Riaz, Maria and Williams, Laurie},
  journal={Journal of Cybersecurity},
  volume={2},
  number={2},
  pages={147--163},
  year={2016},
  publisher={Oxford University Press}
}

@article{riaz2015have,
  title={How have we evaluated software pattern application? A systematic mapping study of research design practices},
  author={Riaz, Maria and Breaux, Travis and Williams, Laurie},
  journal={Information and Software Technology},
  volume={65},
  pages={14--38},
  year={2015},
  publisher={Elsevier}
}

@article{srikanth2014towards,
  title={Towards the prioritization of system test cases},
  author={Srikanth, Hema and Banerjee, Sean and Williams, Laurie and Osborne, Jason},
  journal={Software Testing, Verification and Reliability},
  volume={24},
  number={4},
  pages={320--337},
  year={2014},
  publisher={Wiley Online Library}
}





